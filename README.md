# ğŸ’§ Water Quality Classification System

A production-ready machine learning system for multi-class water quality classification using physical, chemical, and biological parameters.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Usage](#usage)
- [Model Performance](#model-performance)
- [Configuration](#configuration)

---

## ğŸ¯ Overview

This project implements a comprehensive machine learning pipeline for classifying water quality based on various parameters. It includes data preprocessing, feature engineering, multiple classification algorithms, hyperparameter tuning, and a user-friendly web interface.

### **Key Objectives:**
- Automated water quality classification
- Support for multiple ML algorithms
- Handle imbalanced datasets
- Production-ready deployment
- Interactive web interface

### **Dataset:**
- **Source:** Water Quality Monitoring Data
- **Samples:** 222 water samples
- **Features:** 54 parameters (physical, chemical, biological)
- **Target:** Multi-class water quality classification

---

## âœ¨ Features

### **Data Processing**
- âœ… Automated data validation and quality checks
- âœ… Missing value imputation (median for numeric, mode for categorical)
- âœ… Date feature extraction (year, month, day)
- âœ… Outlier detection and handling
- âœ… Feature scaling (Standard/MinMax/Robust)
- âœ… Categorical encoding (Label/Target/One-Hot)

### **Feature Engineering**
- âœ… Domain-specific features (BOD/COD ratio, pH deviation)
- âœ… Automated feature selection using XGBoost
- âœ… Missing value indicators
- âœ… Interaction features

### **Model Training**
- âœ… 4 Classification Algorithms:
  - Decision Tree
  - Random Forest
  - XGBoost
  - Logistic Regression
- âœ… Grid Search CV for hyperparameter tuning
- âœ… Cross-validation
- âœ… SMOTE for class imbalance handling

### **Evaluation**
- âœ… Comprehensive metrics (Accuracy, Precision, Recall, F1, ROC-AUC)
- âœ… Confusion matrices (counts + percentages)
- âœ… ROC curves for all classes
- âœ… Feature importance analysis
- âœ… Model comparison visualizations

### **Deployment**
- âœ… Streamlit web application
- âœ… Real-time predictions
- âœ… Batch predictions from CSV
- âœ… Model performance dashboard

---

## ğŸ“ Project Structure

```
water-quality-classification/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml              # Main configuration
â”‚   â””â”€â”€ model_params.yaml        # Model hyperparameters
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py           # Data loading
â”‚   â”œâ”€â”€ data_validation.py       # Data quality checks
â”‚   â”œâ”€â”€ data_preprocessing.py    # Preprocessing pipeline
â”‚   â””â”€â”€ imbalance_handler.py     # SMOTE for class imbalance
â”‚
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ feature_engineering.py   # Feature creation
â”‚   â””â”€â”€ feature_selection.py     # Feature selection
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_model.py            # Abstract base class
â”‚   â”œâ”€â”€ decision_tree_model.py   # Decision Tree
â”‚   â”œâ”€â”€ random_forest_model.py   # Random Forest
â”‚   â”œâ”€â”€ xgboost_model.py         # XGBoost
â”‚   â””â”€â”€ logistic_regression_model.py  # Logistic Regression
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trainer.py               # Model training
â”‚   â””â”€â”€ hyperparameter_tuner.py  # Grid Search CV
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ metrics.py               # Metrics calculation
â”‚   â””â”€â”€ model_evaluator.py       # Evaluation & visualization
â”‚
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ components.py            # UI components
â”‚   â””â”€â”€ model_interface.py       # Prediction interface
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Original data
â”‚   â””â”€â”€ processed/               # Processed data
â”‚
â”œâ”€â”€ saved_models/                # Trained models
â”‚   â”œâ”€â”€ decision_tree/
â”‚   â”œâ”€â”€ random_forest/
â”‚   â”œâ”€â”€ xgboost/
â”‚   â””â”€â”€ logistic_regression/
â”‚
â”œâ”€â”€ reports/                     # Outputs
â”‚   â”œâ”€â”€ figures/                 # Visualizations
â”‚   â””â”€â”€ metrics/                 # Performance metrics
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks
â”‚
â”œâ”€â”€ main.py                      # Training pipeline
â”œâ”€â”€ app.py                       # Streamlit web app
â”œâ”€â”€ requirements.txt             # Dependencies
â””â”€â”€ README.md                    # This file
```

---

## ğŸ’» Usage

### **1. Data Preparation**
Place your water quality CSV file in `data/raw/` directory.

```bash
cp your_data.csv data/raw/Project\ file.csv
```

### **2. Configure Settings**
Edit `config/config.yaml` to customize:
- Data paths
- Feature engineering options
- Model selection
- Training parameters

```yaml
# Example: Enable SMOTE for imbalanced data
training:
  use_smote: true

# Enable hyperparameter tuning
training:
  hyperparameter_tuning:
    enabled: true
```

### **3. Train Models**
Run the complete training pipeline:

```bash
python main.py
```

This will:
1. Load and validate data
2. Preprocess and engineer features
3. Handle class imbalance (if enabled)
4. Train all models
5. Tune hyperparameters (if enabled)
6. Evaluate and save results

**Output:**
- Trained models â†’ `saved_models/`
- Performance metrics â†’ `reports/metrics/`
- Visualizations â†’ `reports/figures/`

### **4. Run Web Application**
Launch the Streamlit web interface:

```bash
streamlit run app.py
```

Open your browser to `http://localhost:8501`

---

## ğŸ“Š Model Performance

### **Baseline Models (Default Parameters)**

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| Decision Tree | 0.82 | 0.81 | 0.82 | 0.81 |
| Random Forest | 0.89 | 0.88 | 0.89 | 0.91 |
| XGBoost | 0.94 | 0.90 | 0.93 | 0.903 | 0.94 |
| Logistic Regression | 0.76 | 0.75 | 0.76 | 0.75 |

| Model               | Accuracy | Precision | Recall | F1-Score |
| ------------------- | -------- | --------- | ------ | -------- |
| Decision Tree       | 0.83     | 0.86      | 0.83   | 0.85     |
| Random Forest       | 0.92     | 0.86      | 0.92   | 0.89     |
| XGBoost             | 0.94     | 0.93      | 0.93   | 0.94     |
| Logistic Regression | 0.94     | 0.92      | 0.94   | 0.93     |

**Note:** Performance may vary based on data split and preprocessing options.

### **Key Findings:**
- **Best Model:** XGBoost (Accuracy: 91%)
- **Most Important Features:** pH, Dissolved O2, BOD, COD, Temperature
- **Class Imbalance:** Present - SMOTE recommended
- **Optimal Features:** 20-25 features selected by XGBoost

---

## âš™ï¸ Configuration

### **Main Configuration** (`config/config.yaml`)

```yaml
# Data settings
data:
  raw_data_path: "data/raw/Project file.csv"
  target_column: "Use Based Class"
  train_test_split: 0.2

# Feature engineering
features:
  scaling_method: "standard"
  categorical_encoding: "target"
  feature_selection:
    enabled: true
    n_features: 20

# Training
training:
  use_smote: false
  hyperparameter_tuning:
    enabled: false
```

### **Model Parameters** (`config/model_params.yaml`)

Customize hyperparameters for each model:

```yaml
random_forest:
  n_estimators: 200
  max_depth: 15
  min_samples_split: 5
  
xgboost:
  n_estimators: 200
  max_depth: 6
  learning_rate: 0.1
```

---

## ğŸŒ Web Application

### **Features:**
- **Home:** Project overview and model comparison
- **Make Predictions:** Upload CSV and get predictions
- **Model Evaluation:** View detailed metrics and visualizations
- **About:** Project information and methodology

---

## ğŸ“ˆ Results & Outputs

### **Generated Files:**

**Models:**
- `saved_models/{model_name}/model.pkl` - Baseline model
- `saved_models/{model_name}/model_tuned.pkl` - Tuned model
- `saved_models/preprocessor.pkl` - Preprocessing pipeline

**Metrics:**
- `reports/metrics/{model_name}_metrics.json` - Performance metrics

**Visualizations:**
- `reports/figures/{model_name}_confusion_matrix.png`
- `reports/figures/{model_name}_roc_curves.png`
- `reports/figures/{model_name}_feature_importance.png`
- `reports/figures/model_comparison.png`

---

## ğŸ”¬ Methodology

### **Pipeline Steps:**

1. **Data Loading** - Read CSV with proper encoding
2. **Validation** - Check data quality, missing values, outliers
3. **Preprocessing** - Clean, transform, and encode features
4. **Feature Engineering** - Create domain-specific features
5. **Imbalance Handling** - Apply SMOTE if enabled
6. **Feature Selection** - Select top N features using XGBoost
7. **Model Training** - Train all 4 models
8. **Hyperparameter Tuning** - Grid Search CV (optional)
9. **Evaluation** - Calculate metrics and create visualizations
10. **Deployment** - Save models and launch web app

### **Best Practices Implemented:**
- âœ… Stratified train-test split
- âœ… Feature scaling after split (prevent data leakage)
- âœ… Cross-validation for robust evaluation
- âœ… Separate preprocessing for train/test
- âœ… Model versioning (baseline + tuned)

---

##  Acknowledgments

- Water quality dataset providers
- scikit-learn and XGBoost communities
- Streamlit for the amazing web framework
- Open-source ML community

---

*Last Updated: January 2026*
